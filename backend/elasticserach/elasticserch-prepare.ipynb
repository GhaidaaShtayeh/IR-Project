{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-2: Tweets indexing, query processing and visualization\n",
    "\n",
    "##### visualization link : \n",
    "https://docs.google.com/document/d/1BgA0HOoDmrNcvpjpzYpsJ9aDtGa3a0KgY3EQ6CnXRqU/edit?usp=sharing \n",
    "\n",
    "#### Write a python application that :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  prepare the index mapping with the following properties:\n",
    "- the tweet ID should be of type \"keyword\"\n",
    "- the text of tweets should be of type \"text\"\n",
    "- the tweets creation date should be of type \"date\"\n",
    "- coordinates field should be geo_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda5\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "C:\\Users\\DELL\\Anaconda5\\lib\\site-packages\\ipykernel_launcher.py:47: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'tweet'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "import json\n",
    "import datetime\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "#elastic object prepare \n",
    "es = Elasticsearch(\"http://localhost:9200/\")\n",
    "index_name=\"tweet\"\n",
    "\n",
    "# This test is done during development only. \n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    \n",
    "\n",
    "# index settings\n",
    "settings = {\n",
    "\"mappings\": {\n",
    "        \"properties\": {\n",
    "          \"created_at\": {\n",
    "          \"type\": \"date\",\n",
    "          \"fields\": {\n",
    "            \"keyword\": {\n",
    "              \"type\": \"keyword\",\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"id\": {\n",
    "          \"type\": \"keyword\",\n",
    "        },\n",
    "         \"id_str\": {\n",
    "          \"type\": \"keyword\",\n",
    "        },\n",
    "        \"text\": {\n",
    "          \"type\": \"text\"\n",
    "        },\n",
    "        \"coordinates\": {\n",
    "          \"type\": \"geo_point\"\n",
    "        }\n",
    "        }\n",
    "\n",
    "}\n",
    "\n",
    "    }\n",
    "# create index\n",
    "es.indices.create(index=index_name , body=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - reads and inserts tweets into an ES index (call the index 'tweets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file function in order to read a JSON file and save it into list\n",
    "def read_file(file_name):\n",
    "    with open(file_name,encoding=\"utf8\") as f:\n",
    "        while(True):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = json.loads(line)\n",
    "            line['created_at'] = datetime.datetime.strptime(line['created_at'], '%a %b %d %H:%M:%S %z %Y').isoformat()\n",
    "            #cleare the print\n",
    "            yield line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data added successfully into index name :  tweet\n"
     ]
    }
   ],
   "source": [
    "# code for insert list of docs in JSON file into elastic search \n",
    "\n",
    "helpers.bulk(es,read_file(\"D:\\\\tweets\\\\boulder_flood_geolocated_tweets.json\"),index = index_name)\n",
    "\n",
    "print (\"data added successfully into index name : \" , index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  queries that combine creation date with text to search for tweets\n",
    "### first query : filter by date and text :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query2 = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"created_at\": {\n",
    "                            \"gte\": \"2013-12-31T07:14:22+00:00\",\n",
    "                            \"lt\": \"2015-12-31T07:14:22+00:00\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ,\n",
    "            {\"geo_distance\": {\"distance\": \"50000km\",\"coordinates\": {\"lat\":\"-78.96225\",\"lon\":\"100.4083\"}}},\n",
    "\n",
    "            ],\n",
    "                \"must\" :[\n",
    "                    {\n",
    "                    \"match\": {\n",
    "                        \"text\": \"Ringing\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second query : finding tweet published during a certain time interval, withen a certain bounding box and having a certain word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"created_at\": {\n",
    "                            \"gte\": \"2013-12-31T07:14:22+00:00\",\n",
    "                            \"lt\": \"2015-12-31T07:14:22+00:00\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ,\n",
    "                {\n",
    "                \"geo_shape\": {\n",
    "                  \"coordinates\": {\n",
    "                    \"relation\": \"WITHIN\",\n",
    "                    \"shape\": {\n",
    "                      \"coordinates\": [\n",
    "                        [\n",
    "                          [\n",
    "                            -125.15606,\n",
    "                            44.4083\n",
    "                          ],\n",
    "                          [\n",
    "                            -125.15606,\n",
    "                            29.44405\n",
    "                          ],\n",
    "                          [\n",
    "                            -78.96225,\n",
    "                            44.4083\n",
    "                          ]\n",
    "                        ]\n",
    "                      ],\n",
    "                      \"type\": \"Polygon\"\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "                }\n",
    "            ],\n",
    "                \"must\" :[\n",
    "                    {\n",
    "                    \"match\": {\n",
    "                        \"text\": \"Ringing\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda5\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#sending query :\n",
    "resp = es.search(index=index_name, body=search_query2)\n",
    "#resp2 = es.search(index=index_name, body=search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 Hits:\n",
      "2014-01-01T04:57:01+00:00 id : 418244446191239168:  text : Ringing in the #NewYear @BMoCA for their NYE at the Factory event! Surrounded by #art and Warholesque fun :) #Boulder\n"
     ]
    }
   ],
   "source": [
    "# show the result of applying query :\n",
    "print(\"Got %d Hits:\" % resp['hits']['total']['value'])\n",
    "for hit in resp['hits']['hits']:\n",
    "    print(\"%(created_at)s id : %(id)s:  text : %(text)s\" % hit[\"_source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b91f41160b83ffc59c7e17fa6fd02d637d5dcf1d5e59aa2db87d82178661b954"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
